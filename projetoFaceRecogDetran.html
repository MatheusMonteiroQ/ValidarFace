<!DOCTYPE html>
<html lang="pt-BR">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Validação Facial - Detran</title>
    <link rel="stylesheet" href="projetoFace.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>

<body>
    <header class="welcome-header">
        <div class="header-content">
            <h1 onclick="location.href='index.html'">Sistema de Validação Facial</h1>
        </div>
    </header>
    <main class="main-container">
        <div class="card">
            <div class="card-header">
                Validação de Identidade
            </div>
            <div class="card-body">
                <div id="mensagemMovimentoContainer" class="mensagem-movimento-container"></div>
                <br>
                <div id="cameraContainer" class="camera-container">
                    <video id="video" autoplay playsinline></video>
                    <div class="face-guidelines"></div>
                    <canvas id="canvas" style="display: none;"></canvas>
                </div>

                <div class="controls">
                    <button id="validacaoBtn" class="btn-primary" style="display:block;">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                            viewBox="0 0 16 16">
                            <path
                                d="M15 12a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1V6a1 1 0 0 1 1-1h1.172a3 3 0 0 0 2.12-.879l.83-.828A1 1 0 0 1 6.827 3h2.344a1 1 0 0 1 .707.293l.828.828A3 3 0 0 0 12.828 5H14a1 1 0 0 1 1 1v6zM2 4a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2h-1.172a2 2 0 0 1-1.414-.586l-.828-.828A2 2 0 0 0 9.172 2H6.828a2 2 0 0 0-1.414.586l-.828.828A2 2 0 0 1 3.172 4H2z" />
                            <path
                                d="M8 11a2.5 2.5 0 1 1 0-5 2.5 2.5 0 0 1 0 5zm0 1a3.5 3.5 0 1 0 0-7 3.5 3.5 0 0 0 0 7zM3 6.5a.5.5 0 1 1-1 0 .5.5 0 0 1 1 0z" />
                        </svg>
                        Iniciar Captura
                    </button>
                    <button id="captureBtn" class="btn-primary" style="display:none;">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                            viewBox="0 0 16 16">
                            <path
                                d="M15 12a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1V6a1 1 0 0 1 1-1h1.172a3 3 0 0 0 2.12-.879l.83-.828A1 1 0 0 1 6.827 3h2.344a1 1 0 0 1 .707.293l.828.828A3 3 0 0 0 12.828 5H14a1 1 0 0 1 1 1v6zM2 4a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2h-1.172a2 2 0 0 1-1.414-.586l-.828-.828A2 2 0 0 0 9.172 2H6.828a2 2 0 0 0-1.414.586l-.828.828A2 2 0 0 1 3.172 4H2z" />
                            <path
                                d="M8 11a2.5 2.5 0 1 1 0-5 2.5 2.5 0 0 1 0 5zm0 1a3.5 3.5 0 1 0 0-7 3.5 3.5 0 0 0 0 7zM3 6.5a.5.5 0 1 1-1 0 .5.5 0 0 1 1 0z" />
                        </svg>
                        Capturar Foto
                    </button>
                    <button id="retryBtn" class="btn-secondary" style="display: none;">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                            viewBox="0 0 16 16">
                            <path fill-rule="evenodd"
                                d="M8 3a5 5 0 1 1-4.546 2.914.5.5 0 0 0-.908-.417A6 6 0 1 0 8 2v1z" />
                            <path
                                d="M8 4.466V.534a.25.25 0 0 0-.41-.192L5.23 2.308a.25.25 0 0 0 0 .384l2.36 1.966A.25.25 0 0 0 8 4.466z" />
                        </svg>
                        Tentar Novamente
                    </button>
                    <button id="submitBtn" class="btn-success" style="display: none;" onclick="location.href='final.html'">
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor"
                            viewBox="0 0 16 16">
                            <path
                                d="M15.854.146a.5.5 0 0 1 .11.54l-5.819 14.547a.5.5 0 0 1-.926.15L4.893 9.803l-3.737 3.737a.5.5 0 0 1-.708-.708l4-4a.5.5 0 0 1 .674-.118l2.07 1.035 5.319-13.3a.5.5 0 0 1 .54-.11z" />
                        </svg>
                        Enviar para Validação
                    </button>
                </div>

                <div id="results" class="preview-container">
                    <img id="previewImg" style="display: none; max-width: 100%; border-radius: 8px;">
                    <div id="validationResults"></div>
                </div>
            </div>
        </div>
    </main>

    <footer class="footer">
        <div class="footer-content">
            <p>© 2023 DETRN - Departamento Estadual de Trânsito</p>
            <p>Sistema de Validação Facial - Versão 1.0</p>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js"></script>
    <script>
        // Esperar o DOM carregar completamente
        document.addEventListener('DOMContentLoaded', async function () {
            // Elementos DOM
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            const captureBtn = document.getElementById('captureBtn');
            const validacaoBtn = document.getElementById('validacaoBtn');
            const retryBtn = document.getElementById('retryBtn');
            const submitBtn = document.getElementById('submitBtn');
            const resultsDiv = document.getElementById('results');
            const motionWarning = document.getElementById('motionWarning');
            const mensagemMovimentoContainer = document.getElementById('mensagemMovimentoContainer');
            const cameraContainer = document.getElementById('cameraContainer');
            let selfieSegmentation;
            
            let mediaStream = null;
            let isCameraActive = false;

            const AZURE_CONFIG = {
                endpoint: "https://faceapiazureex.cognitiveservices.azure.com",
                key: "3c50d71844b2415bafe6f023470dc0a5",
                detectionModel: "detection_03",  // Modelo mais recente
                recognitionModel: "recognition_04",
                features: [
                    "qualityForRecognition",
                    "accessories",
                    "glasses",
                    "exposure",
                    "noise",
                    "blur",
                    "occlusion",
                    "headPose",
                    "mask"
                ]
            };

            // Estado da aplicação
            let stream = null;
            let lastFrame = null;
            let motionDetected = false;
            let motionCheckInterval;
            let photoBlob = null;
            
            async function initializeSegmentation() {
                selfieSegmentation = new SelfieSegmentation({
                    locateFile: (file) => {
                        return `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`;
                    }
                });
                
                await selfieSegmentation.setOptions({
                    modelSelection: 1, // 1 para modelo geral
                    selfieMode: true
                });
            }

            // 1. Carregar modelos do face-api.js
            async function loadFaceModels() {
                try {
                    await Promise.all([
                        faceapi.nets.tinyFaceDetector.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models'),
                        faceapi.nets.faceLandmark68Net.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models'),
                        faceapi.nets.faceRecognitionNet.loadFromUri('https://justadudewhohacks.github.io/face-api.js/models')
                    ]);
                    console.log("Modelos de face carregados");
                } catch (error) {
                    console.error("Erro ao carregar modelos:", error);
                    resultsDiv.innerHTML = `<p class="invalid">Erro ao carregar recursos de detecção facial</p>`;
                }
            }

            // 2. Iniciar câmera
            async function initCamera() {
                try {
                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                    }

                    stream = await navigator.mediaDevices.getUserMedia({
                        video: {
                            width: { ideal: 1280 },
                            height: { ideal: 720 },
                            facingMode: 'user'
                        },
                        audio: false
                    });

                    video.srcObject = stream;
                    isCameraActive = true;

                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        captureBtn.disabled = false;
                    };

                } catch (err) {
                    console.error("Erro ao acessar câmera:", err);
                    resultsDiv.innerHTML = `<p class="invalid">Erro ao acessar a câmera: ${err.message}</p>`;
                }
            }

            // 3. Detecção de movimento
            // Substitua a função startMotionDetection por esta versão melhorada
            function startMotionDetection() {
                // Limpar intervalo anterior se existir
                if (motionCheckInterval) {
                    clearInterval(motionCheckInterval);
                }

                // Resetar o último frame
                lastFrame = null;

                motionCheckInterval = setInterval(() => {
                    if (!video.videoWidth) return;

                    // Capturar frame atual
                    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                    const currentFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);

                    // Se não tiver último frame, apenas armazene o atual
                    if (!lastFrame) {
                        lastFrame = currentFrame;
                        return;
                    }

                    // Verificar movimento com sensibilidade aumentada
                    const motion = checkMotionImproved(lastFrame, currentFrame);
                    motionDetected = motion > 0.2;  // Threshold mais baixo (era 0.1)

                    // Feedback visual mais claro
                    if (motionDetected) {
                        motionWarning.style.display = 'block';
                        motionWarning.textContent = `⚠ Movimento detectado! (Nível: ${motion.toFixed(2)}) Mantenha-se imóvel.`;
                        captureBtn.disabled = true;

                        // Adicionar efeito visual na câmera
                        //video.style.border = '3px solid #ff0000';
                        //video.style.boxShadow = '0 0 15px #ff0000';
                    } else {
                        motionWarning.style.display = 'none';
                        captureBtn.disabled = false;
                        video.style.border = 'none';
                        video.style.boxShadow = 'none';
                    }

                    // Atualizar o último frame
                    lastFrame = currentFrame;
                }, 1000);  // Verificar a cada 100ms (era 200ms)
            }
            // Melhora a qualidade da imagem capturada
            function enhanceImage(ctx) {
                const imageData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height);
                const data = imageData.data;

                // Ajuste simples de contraste
                for (let i = 0; i < data.length; i += 4) {
                    const r = data[i];
                    const g = data[i + 1];
                    const b = data[i + 2];

                    // Aumenta ligeiramente o contraste
                    data[i] = clamp(r * 1.1);     // Vermelho
                    data[i + 1] = clamp(g * 1.1); // Verde
                    data[i + 2] = clamp(b * 1.1); // Azul
                }

                return imageData;

                function clamp(value) {
                    return Math.max(0, Math.min(255, value));
                }
            }

            // Cria overlays de instrução
            function createOverlay(message) {
                const overlay = document.createElement('div');
                overlay.className = 'validation-overlay';
                overlay.innerHTML = `<p>${message}</p>`;
                document.querySelector('.camera-container').appendChild(overlay);
                return overlay;
            }
            // 4. melhorado* Substitua a função checkMotion por esta versão melhorada
            function checkMotionImproved(frame1, frame2) {
                let diff = 0;
                let count = 0;

                // Analisar mais pixels (reduzir o passo de 16 para 4)
                for (let i = 0; i < frame1.data.length; i += 4) {
                    // Calcular diferença considerando todos os canais de cor
                    diff += Math.abs(frame1.data[i] - frame2.data[i]);     // R
                    diff += Math.abs(frame1.data[i + 1] - frame2.data[i + 1]); // G
                    diff += Math.abs(frame1.data[i + 2] - frame2.data[i + 2]); // B
                    count += 3;
                }

                // Normalizar para 0-1 e ajustar a sensibilidade
                const motionLevel = (diff / count / 255) * 2;  // Multiplicador para aumentar sensibilidade

                return motionLevel;
            }

            // 4. Verificar movimento entre frames
            function checkMotion(frame1, frame2) {
                let diff = 0;
                let count = 0;

                for (let i = 0; i < frame1.data.length; i += 16) {
                    diff += Math.abs(frame1.data[i] - frame2.data[i]);
                    count++;
                }

                return diff / count / 255;
            }

            // 5. Detecção facial com face-api.js
            async function detectFaces(imageElement) {
                const options = new faceapi.TinyFaceDetectorOptions({
                    inputSize: 512,
                    scoreThreshold: 0.5
                });

                return await faceapi.detectAllFaces(imageElement, options)
                    .withFaceLandmarks();
            }

            // 6. Validação no cliente
            async function validateClientSide(blob) {
                const img = await createImageBitmap(blob);
                const tempCanvas = document.createElement('canvas');
                const tempCtx = tempCanvas.getContext('2d');

                tempCanvas.width = img.width;
                tempCanvas.height = img.height;
                tempCtx.drawImage(img, 0, 0);

                const detections = await detectFaces(tempCanvas);

                if (detections.length === 0) {
                    return {
                        isValid: false,
                        issues: ['Nenhum rosto detectado'],
                        details: {}
                    };
                }

                const mainFace = detections.reduce((prev, current) =>
                    (prev.detection.box.width > current.detection.box.width) ? prev : current
                );

                const box = mainFace.detection.box;
                const faceWidthPercent = (box.width / tempCanvas.width) * 100;

                const centerX = tempCanvas.width / 2;
                const centerY = tempCanvas.height / 2;
                const faceCenterX = box.x + (box.width / 2);
                const faceCenterY = box.y + (box.height / 2);

                const offsetX = Math.abs(faceCenterX - centerX) / centerX * 100;
                const offsetY = Math.abs(faceCenterY - centerY) / centerY * 100;

                const landmarks = mainFace.landmarks;
                const leftEye = landmarks.getLeftEye();
                const rightEye = landmarks.getRightEye();

                const eyeDX = rightEye[3].x - leftEye[0].x;
                const eyeDY = rightEye[3].y - leftEye[0].y;
                const eyeAngle = Math.atan2(eyeDY, eyeDX) * 180 / Math.PI;

                const sharpness = calculateFaceSharpness(tempCtx, box);

                // Análise de iluminação (NOVO)
                const imageData = tempCtx.getImageData(0, 0, tempCanvas.width, tempCanvas.height);
                const lighting = analyzeLighting(imageData, box);


                console.log(faceWidthPercent + " - " + offsetX + " - " + offsetY + " - " + sharpness + " - " + Math.abs(eyeAngle) + " - " + lighting.isValid);
                // Combina todos os resultados
                const isValid = (
                    detections.length === 1 &&
                    faceWidthPercent >= 20 &&
                    faceWidthPercent <= 70 &&
                    offsetX < 30 &&
                    offsetY < 30 &&
                    Math.abs(eyeAngle) < 10 &&
                    sharpness > 40
                    //lighting.isValid  // Inclui validação de iluminação
                );

                // Coletar issues
                const issues = [];
                if (detections.length !== 1) issues.push('Deve haver exatamente um rosto');
                //normal largura da cara 30 a 70
                if (faceWidthPercent < 20) issues.push('Rosto muito pequeno');
                if (faceWidthPercent > 70) issues.push('Rosto muito grande');
                //normal offsetx e y é 15
                if (offsetX >= 30) issues.push('Rosto descentralizado horizontalmente');
                if (offsetY >= 30) issues.push('Rosto descentralizado verticalmente');
                if (Math.abs(eyeAngle) >= 10) issues.push('Rosto inclinado');
                if (sharpness <= 40) issues.push('Nitidez insuficiente');
                if (!lighting.isValid) {
                    if (lighting.brightness <= 0.3) issues.push('Imagem muito escura');
                    if (lighting.brightness >= 0.8) issues.push('Imagem muito clara');
                    if (lighting.contrast <= 0.15) issues.push('Contraste insuficiente');
                    if (lighting.uniformity <= 0.7) issues.push('Iluminação desigual nos lados do rosto');
                }

                return {
                    isValid,
                    details: {
                        faceCount: detections.length,
                        faceWidthPercent: faceWidthPercent.toFixed(1),
                        centerOffsetX: offsetX.toFixed(1),
                        centerOffsetY: offsetY.toFixed(1),
                        faceAngle: eyeAngle.toFixed(1),
                        sharpness: sharpness.toFixed(1),
                        lighting: {  // Detalhes de iluminação
                            brightness: lighting.brightness.toFixed(2),
                            contrast: lighting.contrast.toFixed(2),
                            uniformity: lighting.uniformity.toFixed(2)
                        },
                        box: box
                    },
                    issues
                };
            }

            // 7. Calcular nitidez do rosto
            function calculateFaceSharpness(ctx, faceBox) {
                const faceData = ctx.getImageData(
                    Math.max(0, faceBox.x - 10),
                    Math.max(0, faceBox.y - 10),
                    Math.min(ctx.canvas.width, faceBox.width + 20),
                    Math.min(ctx.canvas.height, faceBox.height + 20)
                );

                let sum = 0;
                for (let i = 0; i < faceData.data.length; i += 4) {
                    const gray = 0.299 * faceData.data[i] +
                        0.587 * faceData.data[i + 1] +
                        0.114 * faceData.data[i + 2];
                    sum += gray;
                }
                const mean = sum / (faceData.data.length / 4);

                let variance = 0;
                for (let i = 0; i < faceData.data.length; i += 4) {
                    const gray = 0.299 * faceData.data[i] +
                        0.587 * faceData.data[i + 1] +
                        0.114 * faceData.data[i + 2];
                    variance += Math.pow(gray - mean, 2);
                }
                variance = variance / (faceData.data.length / 4);

                return Math.sqrt(variance);
            }

            // 8. Exibir resultados
            function displayValidationResults(validation, imgElement) {
                const validationDiv = document.getElementById('validationResults');
                validationDiv.innerHTML = '';
                validationDiv.className = 'validation-results';

                if (!validation.isValid) {
                    validationDiv.innerHTML = `
                        <div class="validation-header invalid">❌ Validação Falhou</div>
                        <div class="error-list">
                            <p>Problemas encontrados:</p>
                            <ul>
                                ${validation.issues.map(issue => `<li>${issue}</li>`).join('')}
                            </ul>
                        </div>
                    `;
                    submitBtn.disabled = true;
                    return;
                }

                const lighting = validation.details.lighting;
                const lightingScore = ((lighting.brightness * 0.4) + (lighting.contrast * 0.3) + (lighting.uniformity * 0.3)) * 100;

                validationDiv.innerHTML = `
                    <div class="validation-header">✅ Rosto Válido Detectado</div>
                    
                    <div class="lighting-info">
                        <div class="lighting-header">Análise de Iluminação: ${lightingScore.toFixed(0)}/100</div>
                        <div class="lighting-bar">
                            <div class="lighting-fill" style="width: ${lightingScore}%"></div>
                        </div>
                        <div class="stats-grid">
                            <div class="stat-item">
                                <div class="stat-label">Brilho</div>
                                <div class="stat-value">${(lighting.brightness * 100).toFixed(0)}%</div>
                            </div>
                            <div class="stat-item">
                                <div class="stat-label">Contraste</div>
                                <div class="stat-value">${(lighting.contrast * 100).toFixed(0)}%</div>
                            </div>
                            <div class="stat-item">
                                <div class="stat-label">Uniformidade</div>
                                <div class="stat-value">${(lighting.uniformity * 100).toFixed(0)}%</div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="stats-grid">
                        <div class="stat-item">
                            <div class="stat-label">Tamanho</div>
                            <div class="stat-value">${validation.details.faceWidthPercent}%</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Centralização X</div>
                            <div class="stat-value">${validation.details.centerOffsetX}%</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Centralização Y</div>
                            <div class="stat-value">${validation.details.centerOffsetY}%</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Ângulo</div>
                            <div class="stat-value">${validation.details.faceAngle}°</div>
                        </div>
                        <div class="stat-item">
                            <div class="stat-label">Nitidez</div>
                            <div class="stat-value">${validation.details.sharpness}</div>
                        </div>
                    </div>
                `;
                
                submitBtn.disabled = false;
            }
            
            async function capturePhoto() {
                return new Promise((resolve) => {
                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                        isCameraActive = false;
                    }
                    const canvas = document.getElementById('canvas');
                    const video = document.getElementById('video');

                    // Ajuste fino para garantir qualidade
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    const ctx = canvas.getContext('2d');

                    // Captura com iluminação otimizada
                    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                    video.style.display = 'none';
                    canvas.style.display = 'block';
                    // Processamento adicional para melhorar a foto
                    const imageData = enhanceImage(ctx);
                    ctx.putImageData(imageData, 0, 0);
                    
                    // Converter para Blob com qualidade
                    canvas.toBlob((blob) => {
                        resolve({
                            blob: blob,
                            url: URL.createObjectURL(blob)
                        });
                    }, 'image/jpeg', 0.95); // Qualidade aumentada para 95%
                });
            }

            // Novo fluxo principal
            async function initiateValidationAndCapture() {
                try {

                    // 2. Validação de posicionamento (só começa após movimento ser aprovado)
                    const positionValid = await validateFacePosition(video);

                    if (!positionValid) {
                        throw new Error("Posicionamento facial não atende aos requisitos");
                    }

                    // 3. Só então captura a foto
                    const photoData = await capturePhoto();
                    return photoData;

                } catch (error) {
                    console.error("Falha na validação:", error);
                    throw error; // Propaga o erro para ser tratado pelo chamador
                }
            }

            async function validateFacePosition(videoElement) {
                return new Promise(async (resolve) => {
                    const validationOverlay = createOverlay("Validando posicionamento...");

                    try {
                        const detections = await faceapi.detectAllFaces(videoElement,
                            new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();

                        if (detections.length === 0) {
                            validationOverlay.innerHTML = "<p class='invalid'>Rosto não detectado</p>";
                            setTimeout(() => validationOverlay.remove(), 2000);
                            return resolve(false);
                        }

                        const validation = analyzeFacePosition(detections[0]);

                        if (validation.isValid) {
                            validationOverlay.innerHTML = "<p class='valid'>✅ Posição aprovada!</p>";
                            setTimeout(() => validationOverlay.remove(), 1000);
                            resolve(true);
                        } else {
                            validationOverlay.innerHTML = `
                    <p class='invalid'>❌ Ajuste seu posicionamento:</p>
                    <ul>
                        ${validation.issues.map(issue => `<li>${issue}</li>`).join('')}
                    </ul>
                `;
                            setTimeout(() => validationOverlay.remove(), 3000);
                            resolve(false);
                        }

                    } catch (error) {
                        validationOverlay.remove();
                        console.error("Erro na validação:", error);
                        resolve(false);
                    }
                });
            }

            //10. Tirar Foto
            // 9. Evento de captura
            captureBtn.addEventListener('click', async () => {
                /*try {
                    // 2. Depois continua com a captura normal
                    clearInterval(motionCheckInterval);
                    captureBtn.disabled = true;

                    const quality = 0.92;
                    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                    canvas.toBlob(async (blob) => {
                        photoBlob = blob;
                        const previewUrl = URL.createObjectURL(blob);

                        resultsDiv.innerHTML = `
                            <h3>Pré-validação Facial</h3>
                            <img id="previewImg" src="${previewUrl}" style="max-width: 60%; border-radius: 8px;">
                            <div id="validationResults"></div>
                        `;

                        try {
                            const imgElement = document.getElementById('previewImg');
                            cameraContainer.style.display = 'none';
                            const validation = await validateClientSide(blob);
                            displayValidationResults(validation, imgElement);
                        } catch (error) {
                            console.error("Erro na validação:", error);
                            resultsDiv.innerHTML += `<p class="invalid">Erro durante a validação: ${error.message}</p>`;
                            retryBtn.style.display = 'inline-block';
                        }

                        captureBtn.style.display = 'none';
                        retryBtn.style.display = 'inline-block';
                        submitBtn.style.display = 'inline-block';
                        
                    }, 'image/jpeg', quality);
                } catch (error) {
                    console.error("Erro na validação de movimento:", error);
                    resultsDiv.innerHTML = `<p class="invalid">Erro na validação: ${error.message}</p>`;
                    captureBtn.disabled = false;
                    retryBtn.style.display = 'inline-block';
                }*/
                try {
                    captureBtn.disabled = true;
                    const { blob } = await capturePhoto();
                    
                    // Usar Azure em vez da validação local
                    const validation = await validateWithAzure(blob);
                    const validationResultss = document.getElementById('validationResults');
                    validationResultss.style.display = 'block';
                    // Exibir resultados
                    displayAzureResults(validation);
                    
                } catch (error) {
                    console.error("Erro na captura:", error);
                    resultsDiv.innerHTML = `<p class="error">Erro: ${error.message}</p>`;
                    captureBtn.disabled = false;
                }
            });
            function showComparison(originalBlob, whiteBgBlob) {
                const originalUrl = URL.createObjectURL(originalBlob);
                const whiteBgUrl = URL.createObjectURL(whiteBgBlob);
                
                resultsDiv.innerHTML = `
                    <div class="preview-container">
                        <img src="${originalUrl}" class="original-bg" style="width: ${originalBlob.width}px">
                        <img src="${whiteBgUrl}" class="white-bg" style="width: ${originalBlob.width}px">
                    </div>
                    <p>Imagem processada com fundo branco</p>
                `;
            }

            // 9. Evento de captura
            validacaoBtn.addEventListener('click', async () => {
                try {
                    // 1. Primeiro valida o movimento da cabeça
                    await validateHeadMovement(video);
                    // 2. Depois continua com a captura normal
                    clearInterval(motionCheckInterval);
                    captureBtn.disabled = false;
                    captureBtn.style.display = 'block';
                    validacaoBtn.style.display = 'none';
                } catch (error) {
                    console.error("Erro na validação de movimento:", error);
                    resultsDiv.innerHTML = `<p class="invalid">Erro na validação: ${error.message}</p>`;
                    validacaoBtn.disabled = false;
                }
            });

            // 10. Evento de tentar novamente
            retryBtn.addEventListener('click', () => {
                resultsDiv.innerHTML = '';
                retryBtn.style.display = 'none';
                submitBtn.style.display = 'none';
                validacaoBtn.disabled = false;
                validacaoBtn.style.display = 'block';
                captureBtn.style.display = 'none';
                cameraContainer.style.display = 'block';
                const validationResultss = document.getElementById('validationResults');
                validationResultss.style.display = 'none';
                canvas.style.display = 'none';
                video.style.display = 'block';
                initCamera();

            });

            // 11. Inicializar a aplicação
            await loadFaceModels();
            await initCamera();

            
        // Exibir resultados do Azure
        function displayAzureResults(validation) {
            const validationDiv = document.getElementById('validationResults');
            validationDiv.innerHTML = '';
            
            if (!validation.isValid) {
                validationDiv.innerHTML = `
                    <div class="azure-header invalid">
                        ❌ Validação ICAO Falhou
                    </div>
                    <div class="azure-issues">
                        <h4>Problemas encontrados:</h4>
                        <ul>
                            ${validation.issues.map(issue => `<li>${issue}</li>`).join('')}
                        </ul>
                    </div>
                    <div class="azure-details">
                        <button id="showDetails" class="btn-details">
                            Mostrar detalhes técnicos
                        </button>
                        <div id="technicalDetails" style="display:none">
                            <pre>${JSON.stringify(validation.details, null, 2)}</pre>
                        </div>
                    </div>
                `;
                
                document.getElementById('showDetails').addEventListener('click', () => {
                    const detailsDiv = document.getElementById('technicalDetails');
                    detailsDiv.style.display = detailsDiv.style.display === 'none' ? 'block' : 'none';
                });
            } else {
                validationDiv.innerHTML = `
                    <div class="azure-header valid">
                        ✅ Foto Aprovada para Documentos
                    </div>
                    <div class="azure-success">
                        <p>Sua foto atende a todos os requisitos ICAO para documentos oficiais.</p>
                        <div class="quality-indicator">
                            <div class="quality-bar" style="width:100%"></div>
                        </div>
                    </div>
                `;
            }
            
            submitBtn.disabled = !validation.isValid;
            retryBtn.style.display = 'inline-block';
            submitBtn.style.display = 'inline-block';
        };
        // 13. Validacao Luz
        // Adicione estas funções ao seu código existente

        /**
         * Analisa a iluminação do rosto na imagem
         * @param {ImageData} imageData - Dados da imagem
         * @param {Object} faceBox - Caixa delimitadora do rosto {x, y, width, height}
         * @returns {Object} Resultados da análise
         */
        function analyzeLighting(imageData, faceBox) {
            // Extrair região do rosto
            const facePixels = getFacePixels(imageData, faceBox);

            // 1. Calcular brilho médio
            const brightness = calculateBrightness(facePixels);

            // 2. Calcular contraste
            const contrast = calculateContrast(facePixels);

            // 3. Verificar uniformidade (diferença entre lados)
            const uniformity = checkUniformity(imageData, faceBox);

            return {
                brightness: brightness,
                contrast: contrast,
                uniformity: uniformity,
                isValid: (
                    brightness > 0.3 && brightness < 0.8 &&  // Valores normalizados (0-1)
                    contrast > 0.15 &&                       // Diferença mínima entre claro/escuro
                    uniformity > 0.7                         // Similaridade entre lados (0-1)
                ),
                issues: []
            };
        }

        async function capturePhoto() {
            return new Promise((resolve) => {
                const canvas = document.getElementById('canvas');
                const video = document.getElementById('video');

                // Ajuste fino para garantir qualidade
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                const ctx = canvas.getContext('2d');

                // Captura com iluminação otimizada
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                // Processamento adicional para melhorar a foto
                const imageData = enhanceImage(ctx);
                ctx.putImageData(imageData, 0, 0);

                // Converter para Blob com qualidade
                canvas.toBlob((blob) => {
                    resolve({
                        blob: blob,
                        url: URL.createObjectURL(blob)
                    });
                }, 'image/jpeg', 0.95); // Qualidade aumentada para 95%
            });
        }
        // Helper: Extrai pixels da região facial
        function getFacePixels(imageData, faceBox) {
            const pixels = [];
            
            // Verificação de limites
            const startX = Math.max(0, Math.floor(faceBox.x));
            const startY = Math.max(0, Math.floor(faceBox.y));
            const endX = Math.min(imageData.width, Math.ceil(faceBox.x + faceBox.width));
            const endY = Math.min(imageData.height, Math.ceil(faceBox.y + faceBox.height));

            for (let y = startY; y < endY; y++) {
                for (let x = startX; x < endX; x++) {
                    const i = (y * imageData.width + x) * 4;
                    
                    // Verificação de índice válido
                    if (i >= 0 && i + 2 < imageData.data.length) {
                        pixels.push({
                            r: imageData.data[i],
                            g: imageData.data[i + 1],
                            b: imageData.data[i + 2]
                        });
                    }
                }
            }
            
            console.log(`Pixels capturados: ${pixels.length}`);
            return pixels;
        }

        // Helper: Calcula brilho médio (0-1)
        function calculateBrightness(pixels) {
            // Verificação de segurança
            if (!pixels || !pixels.length) {
                console.error("Array de pixels vazio ou inválido");
                return 0.5; // Valor padrão caso falhe
            }

            let sum = 0;
            let validPixels = 0;
            
            // Usando for loop tradicional que é mais seguro
            for (let i = 0; i < pixels.length; i++) {
                const pixel = pixels[i];
                
                // Verificação de pixel válido
                if (pixel && typeof pixel.r !== 'undefined' && 
                    typeof pixel.g !== 'undefined' && 
                    typeof pixel.b !== 'undefined') {
                    
                    // Cálculo da luminância com clamp para valores inválidos
                    const r = Math.max(0, Math.min(255, pixel.r));
                    const g = Math.max(0, Math.min(255, pixel.g));
                    const b = Math.max(0, Math.min(255, pixel.b));
                    
                    sum += (0.299 * r + 0.587 * g + 0.114 * b) / 255;
                    validPixels++;
                }
            }

            // Proteção contra divisão por zero
            return validPixels > 0 ? sum / validPixels : 0.5;
        }

        // Helper: Calcula contraste (diferença entre quartis)
        function calculateContrast(pixels) {
            const luminances = pixels.map(p =>
                (0.299 * p.r + 0.587 * p.g + 0.114 * p.b) / 255
            ).sort((a, b) => a - b);

            // Diferença entre Q3 e Q1 (quartis)
            const q1 = luminances[Math.floor(luminances.length * 0.25)];
            const q3 = luminances[Math.floor(luminances.length * 0.75)];
            return q3 - q1;
        }

        // Helper: Verifica uniformidade entre lados do rosto
        function checkUniformity(imageData, faceBox) {
            try {
                // 1. Obter pixels de cada lado do rosto
                const leftSide = getFaceHalfPixels(imageData, faceBox, 'left');
                const rightSide = getFaceHalfPixels(imageData, faceBox, 'right');
                
                // Verificar se temos pixels suficientes
                if (leftSide.length === 0 || rightSide.length === 0) {
                    console.warn("Um dos lados do rosto não possui pixels válidos");
                    return 0.7; // Valor padrão seguro
                }

                // 2. Comparar histogramas de brilho
                const similarity = compareHistograms(leftSide, rightSide);
                
                // Garantir que o retorno está entre 0 e 1
                return Math.max(0, Math.min(1, similarity || 0.7));
                
            } catch (error) {
                console.error("Erro ao calcular uniformidade:", error);
                return 0.7; // Valor padrão em caso de erro
            }
        }

        // Helper: Extrai pixels de um lado do rosto
        function getFaceHalfPixels(imageData, faceBox, side) {
            // Garantir valores inteiros e dentro dos limites
            const startX = Math.max(0, Math.floor(faceBox.x));
            const startY = Math.max(0, Math.floor(faceBox.y));
            const width = Math.floor(faceBox.width);
            const height = Math.floor(faceBox.height);
            
            const halfWidth = Math.floor(width / 2);
            const endY = Math.min(imageData.height, startY + height);
            
            // Definir área de cada lado
            let areaStartX, areaEndX;
            
            if (side === 'left') {
                areaStartX = startX;
                areaEndX = startX + halfWidth;
            } else {
                areaStartX = startX + halfWidth;
                areaEndX = startX + width;
            }
            
            // Limitar às dimensões da imagem
            areaEndX = Math.min(imageData.width, areaEndX);
            
            const pixels = [];
            
            for (let y = startY; y < endY; y++) {
                for (let x = areaStartX; x < areaEndX; x++) {
                    const i = (y * imageData.width + x) * 4;
                    
                    // Verificar se o índice está dentro dos limites
                    if (i >= 0 && i + 2 < imageData.data.length) {
                        const r = imageData.data[i];
                        const g = imageData.data[i + 1];
                        const b = imageData.data[i + 2];
                        
                        // Calcular luminância e garantir que é um número válido
                        const luminance = (0.299 * r + 0.587 * g + 0.114 * b) / 255;
                        if (!isNaN(luminance)) {
                            pixels.push(luminance);
                        }
                    }
                }
            }
            
            console.log(`Pixels no lado ${side}:`, pixels.length);
            return pixels;
        }

// Função para detectar boné localmente
async function detectHat(blob, faceRectangle) {
    const img = await createImageBitmap(blob);
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    canvas.width = img.width;
    canvas.height = img.height;
    ctx.drawImage(img, 0, 0);
    
    // Analisar região acima do rosto
    const headTop = {
        x: faceRectangle.left,
        y: Math.max(0, faceRectangle.top - faceRectangle.height * 0.5), // 50% acima do rosto
        width: faceRectangle.width,
        height: faceRectangle.height * 0.5
    };
    
    // Obter pixels da região
    const imageData = ctx.getImageData(headTop.x, headTop.y, headTop.width, headTop.height);
    const brightness = calculateRegionBrightness(imageData);
    
    // Se a região for muito escura (comparada ao rosto), pode ser um boné
    const faceImageData = ctx.getImageData(
        faceRectangle.left, 
        faceRectangle.top, 
        faceRectangle.width, 
        faceRectangle.height
    );
    const faceBrightness = calculateRegionBrightness(faceImageData);
    
    // Se a região acima for significativamente mais escura que o rosto
    return brightness < (faceBrightness * 0.7);
}

// Função auxiliar para calcular brilho de uma região
function calculateRegionBrightness(imageData) {
    let sum = 0;
    const data = imageData.data;
    
    for (let i = 0; i < data.length; i += 4) {
        sum += (0.299 * data[i] + 0.587 * data[i+1] + 0.114 * data[i+2]) / 255;
    }
    
    return sum / (data.length / 4);
}
        // Função principal para validação com Azure
        async function validateWithAzure(blob) {
            try {
                // 1. Converter blob para base64
                const imageBase64 = await blobToBase64(blob);
                
                // 2. Chamar Azure Face API
                const detectionResult = await callAzureFaceAPI(imageBase64);
                
                // 3. Validar conforme padrão ICAO
                const validation = await validateICAO(detectionResult,blob);

                return {
                    isValid: validation.isValid,
                    issues: validation.issues,
                    details: detectionResult
                };
                
            } catch (error) {
                console.error("Erro na validação com Azure:", error);
                return {
                    isValid: false,
                    issues: ["Erro durante a validação com o serviço Azure"],
                    details: null
                };
            }
        }

        // Converter Blob para Base64
        function blobToBase64(blob) {
            return new Promise((resolve) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    const base64data = reader.result.split(',')[1];
                    resolve(base64data);
                };
                reader.readAsDataURL(blob);
            });
        }

        // Chamar o Azure Face API
        async function callAzureFaceAPI(imageBase64) {
            const AZURE_CONFIG = {
                endpoint: "https://faceapiazureex.cognitiveservices.azure.com",
                key: "3c50d71844b2415bafe6f023470dc0a5",
                detectionModel: "detection_03",  // Modelo mais recente
                recognitionModel: "recognition_04",
                features: [
                    "qualityForRecognition",
                    "accessories",
                    "glasses",
                    "exposure",
                    "noise",
                    "blur",
                    "occlusion",
                    "headPose",
                    "mask"
                ]
            };

            const url = `${AZURE_CONFIG.endpoint}/face/v1.0/detect?` +
                        `detectionModel=${AZURE_CONFIG.detectionModel}&` +
                        `recognitionModel=${AZURE_CONFIG.recognitionModel}&` +
                        `returnFaceAttributes=${AZURE_CONFIG.features.join(',')}`;
            const conteudoImg = base64ToArrayBuffer(imageBase64);
            const response = await fetch("https://faceapiazureex.cognitiveservices.azure.com/face/v1.0/detect?detectionModel=detection_03&recognitionModel=recognition_04&returnFaceAttributes=qualityForRecognition,glasses,exposure,blur,occlusion,headPose,mask", {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/octet-stream',
                    'Ocp-Apim-Subscription-Key': AZURE_CONFIG.key
                },
                body: conteudoImg
            });

            if (!response.ok) {
                throw new Error(`Azure API error: ${response.statusText}`);
            }

            return await response.json();
        }
        // Converter Base64 para ArrayBuffer
        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes;
        }

        // Validar conforme padrão ICAO
        async function validateICAO(azureResult,blob) {
            if (!azureResult || azureResult.length === 0) {
                return { isValid: false, issues: ["Nenhum rosto detectado"] };
            }

            if (azureResult.length > 1) {
                return { isValid: false, issues: ["Mais de um rosto detectado"] };
            }

            const face = azureResult[0];
            const attributes = face.faceAttributes;
            const backgroundValidation = await validateWhiteBackground(blob, face.faceRectangle);

            const issues = [];
            const whiteBgImage = await removeBackgroundWithRemoveBg(blob);
        
                    // Agora você pode usar whiteBgImage que tem fundo branco
                    const previewUrl = URL.createObjectURL(whiteBgImage);
                    let previewImg = document.getElementById('previewImg');
                    previewImg.src = previewUrl;
                    previewImg.style.display = 'block';

            // 1. Qualidade básica
            if (attributes.qualityForRecognition !== 'high') {
                issues.push("Qualidade da imagem insuficiente para reconhecimento");
            }

            // 2. Acessórios
            if (attributes.accessories && attributes.accessories.length > 0) {
                issues.push("Acessórios não permitidos detectados");
            }

            if (attributes.glasses !== 'NoGlasses') {
                issues.push("Óculos não permitidos detectados");
            }

            // 3. Oclusões
            if (attributes.occlusion.eyeOccluded){
                issues.push("Os olhos estão obstruídos");
            }

            if(attributes.occlusion.mouthOccluded){
                issues.push("A boca está obstruída");
            }

            if(attributes.occlusion.foreheadOccluded){
                issues.push("Boné ou acessório na cabeça detectado");
            }

            // 4. Exposição e iluminação
            if (attributes.exposure.exposureLevel !== 'goodExposure') {
                issues.push("Problemas de exposição/iluminação");
            }

            // 5. Nitidez
            if (attributes.blur.blurLevel !== 'low' && attributes.blur.blurLevel !== 'medium') {
                issues.push("Imagem muito borrada");
            }

            // 6. Posição da cabeça
            if (Math.abs(attributes.headPose.yaw) > 20 || 
                Math.abs(attributes.headPose.pitch) > 15) {
                issues.push("Rosto não está frontal à câmera");
            }
            /*
            if (!backgroundValidation.isWhite) {
                issues.push(`Fundo não é branco (${backgroundValidation.whitePercentage.toFixed(1)}% de pixels brancos)`);
            }*/
            return {
                isValid: issues.length === 0,
                issues: issues,
                details: face
            };
        }

        // Helper: Compara histogramas de brilho (0-1)
        function compareHistograms(set1, set2) {
            // Verificar conjuntos válidos
            if (!set1 || !set2 || set1.length === 0 || set2.length === 0) {
                console.warn("Conjuntos de dados inválidos para comparação de histogramas");
                return 0.7; // Valor padrão seguro
            }

            const bins = 8;
            const hist1 = new Array(bins).fill(0);
            const hist2 = new Array(bins).fill(0);
            
            // Construir histogramas com proteção contra valores inválidos
            set1.forEach(val => {
                if (typeof val === 'number' && !isNaN(val)) {
                    const bin = Math.min(Math.floor(val * bins), bins - 1);
                    hist1[bin]++;
                }
            });
            
            set2.forEach(val => {
                if (typeof val === 'number' && !isNaN(val)) {
                    const bin = Math.min(Math.floor(val * bins), bins - 1);
                    hist2[bin]++;
                }
            });
            
            // Normalizar os histogramas
            const total1 = Math.max(1, set1.length); // Evitar divisão por zero
            const total2 = Math.max(1, set2.length);
            
            for (let i = 0; i < bins; i++) {
                hist1[i] /= total1;
                hist2[i] /= total2;
            }
            
            // Calcular similaridade cosseno com proteção
            let dot = 0, mag1 = 0, mag2 = 0;
            
            for (let i = 0; i < bins; i++) {
                dot += hist1[i] * hist2[i];
                mag1 += hist1[i] * hist1[i];
                mag2 += hist2[i] * hist2[i];
            }
            
            const magProduct = Math.sqrt(mag1) * Math.sqrt(mag2);
            
            // Proteção contra divisão por zero
            if (magProduct === 0) {
                console.warn("Produto das magnitudes é zero");
                return 0.7; // Valor padrão seguro
            }
            
            const similarity = dot / magProduct;
            
            // Garantir que o resultado está entre 0 e 1
            return Math.max(0, Math.min(1, similarity));
        }

        // Adicione esta função junto com as outras funções auxiliares
        // Substitua a função validateHeadMovement por esta versão corrigida
        async function validateHeadMovement(videoElement) {
            return new Promise(async (resolve, reject) => {
                // Configuração do overlay
                const overlay = document.createElement('div');
                overlay.style.cssText = `
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: rgba(0,0,0,0.7); color: white; z-index: 1000;
            display: flex; flex-direction: column; justify-content: center;
            align-items: center; text-align: center; font-size: 1.2em;
        `;

                const statusDiv = document.createElement('div');
                statusDiv.style.cssText = `
            margin: 5px; font-size: 14px; font-weight: bold;
            min-height: 2em;
        `;

                const progressBar = document.createElement('div');
                progressBar.style.cssText = `
            width: 80%; height: 20px; background: #333;
            border-radius: 10px; margin: 5px; overflow: hidden;
        `;

                const progressFill = document.createElement('div');
                progressFill.style.cssText = `
            height: 100%; width: 0%; background: #4CAF50;
            transition: width 0.3s;
        `;

                progressBar.appendChild(progressFill);
                overlay.innerHTML = `<h5>Validação de Movimento</h3>`;
                overlay.appendChild(statusDiv);
                overlay.appendChild(progressBar);

                document.querySelector('.mensagem-movimento-container').appendChild(overlay);

                // Estados da validação
                const steps = [
                    { instruction: "LEVANTE a cabeça e olhe para CIMA", target: 'up', duration: 2000 },
                    { instruction: "AGORA ABAIXE a cabeça e olhe para BAIXO", target: 'down', duration: 2000 },
                    { instruction: "VOLTE para POSIÇÃO NORMAL", target: 'center', duration: 1000 }
                ];

                mensagemMovimentoContainer.style.display = 'block';

                let currentStep = 0;
                let progress = 0;
                let correctDirectionTime = 0;
                let lastDirection = '';
                let lastTime = Date.now();

                // Função para atualizar a interface
                function updateUI() {
                    statusDiv.textContent = steps[currentStep].instruction;
                    progressFill.style.width = `${progress}%`;
                }

                updateUI();

                // Verificação contínua
                const checkInterval = setInterval(async () => {
                    try {
                        const now = Date.now();
                        const deltaTime = now - lastTime;
                        lastTime = now;

                        const detections = await faceapi.detectAllFaces(videoElement,
                            new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();

                        if (detections.length === 0) {
                            statusDiv.textContent = "Rosto não detectado! Posicione-se no círculo";
                            progress = Math.max(0, progress - 5);
                            updateUI();
                            return;
                        }

                        const currentDirection = getHeadDirection(detections[0].landmarks);

                        // Verificar se a direção mudou
                        if (currentDirection !== lastDirection) {
                            correctDirectionTime = 0;
                            lastDirection = currentDirection;
                        } else {
                            correctDirectionTime += deltaTime;
                        }

                        // Verificar se está na direção correta
                        if (currentDirection === steps[currentStep].target) {
                            // Calcular progresso baseado no tempo na posição correta
                            const progressIncrement = (deltaTime / steps[currentStep].duration) * 100;
                            progress = Math.min(100, progress + progressIncrement);

                            // Se completou o tempo necessário na posição correta
                            if (correctDirectionTime >= steps[currentStep].duration) {
                                progress = 100;
                                updateUI();

                                // Avançar para o próximo passo
                                currentStep++;
                                progress = 0;
                                correctDirectionTime = 0;

                                // Se completou todos os passos
                                if (currentStep >= steps.length) {
                                    clearInterval(checkInterval);
                                    overlay.remove();
                                    mensagemMovimentoContainer.style.display = 'none';
                                    resolve();
                                    return;
                                }
                            }
                        } else {
                            progress = Math.max(0, progress - (deltaTime / 200));
                        }

                        updateUI();

                    } catch (error) {
                        console.error("Erro na validação:", error);
                        progress = Math.max(0, progress - 5);
                        updateUI();
                    }
                }, 100);

                // Timeout
                setTimeout(() => {
                    clearInterval(checkInterval);
                    overlay.remove();
                    reject(new Error("Tempo excedido para validação de movimento"));
                }, 60000);
            });
        }

        function getHeadDirection(landmarks) {
            const nose = landmarks.getNose();
            const jaw = landmarks.getJawOutline();
            const leftEye = landmarks.getLeftEye();
            const rightEye = landmarks.getRightEye();

            // Pontos-chave
            const noseTip = nose[3];       // Ponta do nariz
            const chin = jaw[8];           // Centro do queixo
            const leftEyeCorner = leftEye[0];
            const rightEyeCorner = rightEye[3];

            // Calcular pontos médios
            const eyesCenter = {
                x: (leftEyeCorner.x + rightEyeCorner.x) / 2,
                y: (leftEyeCorner.y + rightEyeCorner.y) / 2
            };

            // Distâncias importantes
            const noseToChin = Math.sqrt(Math.pow(noseTip.x - chin.x, 2) + Math.pow(noseTip.y - chin.y, 2));
            const eyesToChin = Math.sqrt(Math.pow(eyesCenter.x - chin.x, 2) + Math.pow(eyesCenter.y - chin.y, 2));

            // Razão crítica para determinar direção
            const ratio = noseToChin / eyesToChin;
            console.log("Razão:", ratio);

            // Limiares ajustados após testes
            if (ratio > 0.73) {
                return 'up';    // Cabeça erguida
            } else if (ratio < 0.55) {
                return 'down';  // Cabeça abaixada
            } else {
                return 'center'; // Posição normal
            }
        }

        

        // Adicione esta função ao seu código
        async function validateWhiteBackground(blob, faceRectangle) {
            const img = await createImageBitmap(blob);
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            
            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0);
            
            // Definir margem ao redor do rosto para análise
            const margin = 20;
            
            // Área a ser analisada (toda a imagem exceto a área do rosto com margem)
            const backgroundArea = {
                x: 0,
                y: 0,
                width: canvas.width,
                height: canvas.height,
                exclude: {
                    x: Math.max(0, faceRectangle.left - margin),
                    y: Math.max(0, faceRectangle.top - margin),
                    width: Math.min(canvas.width, faceRectangle.width + margin * 2),
                    height: Math.min(canvas.height, faceRectangle.height + margin * 2)
                }
            };
            
            // Analisar pixels do fundo
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const backgroundPixels = getBackgroundPixels(imageData, backgroundArea);
            
            // Calcular porcentagem de pixels brancos
            const whiteThreshold = 230; // Valor RGB mínimo para considerar como "branco" (0-255)
            let whitePixels = 0;
            
            for (let i = 0; i < backgroundPixels.length; i += 4) {
                if (backgroundPixels[i] > whiteThreshold &&     // R
                    backgroundPixels[i+1] > whiteThreshold &&   // G
                    backgroundPixels[i+2] > whiteThreshold) {   // B
                    whitePixels++;
                }
            }
            
            const whitePercentage = (whitePixels / (backgroundPixels.length / 4)) * 100;
            
            // Considerar como fundo branco se pelo menos 85% dos pixels forem brancos
            return {
                isWhite: whitePercentage >= 85,
                whitePercentage: whitePercentage
            };
        }

        // Função auxiliar para obter pixels do fundo
        function getBackgroundPixels(imageData, area) {
            const pixels = [];
            const data = imageData.data;
            
            for (let y = 0; y < area.height; y++) {
                for (let x = 0; x < area.width; x++) {
                    // Pular área do rosto
                    if (x >= area.exclude.x && x < area.exclude.x + area.exclude.width &&
                        y >= area.exclude.y && y < area.exclude.y + area.exclude.height) {
                        continue;
                    }
                    
                    const idx = (y * imageData.width + x) * 4;
                    pixels.push(data[idx], data[idx+1], data[idx+2], data[idx+3]);
                }
            }
            
            return pixels;
        }

        async function removeBackgroundWithAzure(imageBase64) {
            const endpoint = "https://customvisionicao.cognitiveservices.azure.com";
            const apiUrl = `${endpoint}/computervision/imageanalysis:segment?api-version=2023-02-01-preview&mode=backgroundRemoval`;
            const conteudoImg = base64ToArrayBuffer(imageBase64);
            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/octet-stream',
                    'Ocp-Apim-Subscription-Key': '8GQlGfw2iPrCQcMUa4kJnrByWbc8PTIXKrFWFXV9RQy1y4HCtSpXJQQJ99BDACYeBjFXJ3w3AAAJACOG3Q56'
                },
                body: conteudoImg
            });
            
            if (!response.ok) throw new Error('Falha na remoção do fundo');
            return await response.blob();
        }


// Função para aplicar fundo branco
async function applyWhiteBackground(blob) {
    const img = await createImageBitmap(blob);
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    canvas.width = img.width;
    canvas.height = img.height;
    
    // Preencher com branco
    ctx.fillStyle = 'white';
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    
    // Desenhar a imagem sem fundo
    ctx.drawImage(img, 0, 0);
    
    return new Promise((resolve) => {
        canvas.toBlob(resolve, 'image/jpeg', 0.92);
    });
}

async function removeBackgroundWithRemoveBg(blob) {
    const apiKey = 'U8hQiXuTaQEX5tHoBs4kV2ok'; // <- substitua aqui

    const formData = new FormData();
    formData.append("image_file", blob);
    formData.append("size", "auto");

    const response = await fetch("https://api.remove.bg/v1.0/removebg", {
        method: "POST",
        headers: {
            "X-Api-Key": apiKey,
        },
        body: formData
    });

    if (!response.ok) {
        const errText = await response.text();
        throw new Error(`Erro do Remove.bg: ${errText}`);
    }

    const resultBlob = await response.blob();

    // Joga fundo branco por trás da imagem transparente
    return await composeWithWhiteBackground(resultBlob);
}

async function composeWithWhiteBackground(foregroundBlob) {
    const fgImg = await createImageBitmap(foregroundBlob);

    const canvas = document.createElement('canvas');
    canvas.width = fgImg.width;
    canvas.height = fgImg.height;

    const ctx = canvas.getContext('2d');

    // Fundo branco
    ctx.fillStyle = "#ffffff";
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    // Imagem recortada por cima
    ctx.drawImage(fgImg, 0, 0);

    return new Promise((resolve) => {
        canvas.toBlob((finalBlob) => {
            resolve(finalBlob);
        }, 'image/jpeg', 0.95);
    });
}

            // 12. Limpeza
            window.addEventListener('beforeunload', () => {
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
                clearInterval(motionCheckInterval);
            });
        });


    </script>
</body>

</html>
